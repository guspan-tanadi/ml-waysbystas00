{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7428a31f",
   "metadata": {},
   "source": [
    "#  bf16, fp16 or fp32 pretraining detection\n",
    "\n",
    "The goal is to autodetect if a model has been trained in bf16, fp16 or fp32 precision. We want this since we know that bf16-pretrained models tend to overflow when consequently finetuned with fp16 (mixed).\n",
    "\n",
    "We know that fp16's max number is `2**16=65536`, so it should be easy to look at the weights and if they are large then the model has most likely be trained in other than fp16 precision (mixed or not).\n",
    "\n",
    "Let's write a script to look at the absolute min/max values of any model's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e951074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "028d21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b70ce36",
   "metadata": {},
   "source": [
    "## Module weights abs min/max analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa0b9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_min_max(modules, verbose=True):\n",
    "    \"\"\"\n",
    "    modules is a list of sub-modules to search recursively. \n",
    "    \n",
    "    this can be the whole model, but sometimes only some submodules want to be inspected\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"\\nSearching:\")\n",
    "        print(\"module | params\")\n",
    "    abs_min, abs_max = 10000, 0\n",
    "    for i,m in enumerate(modules):\n",
    "        for j,p in enumerate(m.parameters(recurse=True)):\n",
    "            p_abs = p.abs()\n",
    "            p_abs_max = p_abs.max().item()\n",
    "            p_abs_min = p_abs.min().item()\n",
    "            if p_abs_min < abs_min: abs_min = p_abs_min\n",
    "            if p_abs_max > abs_max: abs_max = p_abs_max\n",
    "        if verbose:\n",
    "            print(f\"{i:>6} | {j}\")\n",
    "    return abs_min, abs_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a43e2",
   "metadata": {},
   "source": [
    "the only concern I have here is that some models when trained in mixed precision may have some segment trained in fp32 and may end up with larger weights, though it is very unlikely since these then have to interact with the rest of the system. But more thought is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "197c886d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching:\n",
      "module | params\n",
      "     0 | 48\n",
      "     1 | 78\n",
      "\n",
      "Results:\n",
      "abs min   | abs max\n",
      "5.442e-09 | 6.850e+01\n",
      "\n",
      "Searching:\n",
      "module | params\n",
      "     0 | 130\n",
      "\n",
      "Results:\n",
      "abs min   | abs max\n",
      "5.442e-09 | 7.920e+02\n"
     ]
    }
   ],
   "source": [
    "# Let's look at t5-small in verbose mode\n",
    "model = AutoModel.from_pretrained(\"t5-small\")\n",
    "\n",
    "# let's look at just transformer blocks\n",
    "abs_min, abs_max = abs_min_max([model.encoder.block, model.decoder.block])\n",
    "print(\"\\nResults:\")\n",
    "print(\"abs min   | abs max\")\n",
    "print(f\"{abs_min:.3e} | {abs_max:.3e}\")\n",
    "\n",
    "# now the whole model\n",
    "abs_min, abs_max = abs_min_max([model])\n",
    "print(\"\\nResults:\")\n",
    "print(\"abs min   | abs max\")\n",
    "print(f\"{abs_min:.3e} | {abs_max:.3e}\")\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48185d16",
   "metadata": {},
   "source": [
    "## Multiple model weights abs min/max analyser\n",
    "\n",
    "Now let's write a nice wrapper to process many models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bcf8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_abs_min_max(mnames):\n",
    "    transformers.logging.set_verbosity_error() # be quiet\n",
    "    print(f\"{'name':^40} | {'abs min':^9} | {'abs max':^9} \")\n",
    "    print(f\"{'-'*40}-|-{'-'*9}-|-{'-'*9}-\")\n",
    "    for mname in mnames:\n",
    "        model = AutoModel.from_pretrained(mname)\n",
    "        abs_min, abs_max = abs_min_max([model], verbose=False)\n",
    "        print(f\"{mname:<40} | {abs_min:.3e} | {abs_max:.3e}\")\n",
    "        del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266fb1a",
   "metadata": {},
   "source": [
    "## bf16 models\n",
    "\n",
    "Let's look at bf16-pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1479a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name                   |  abs min  |  abs max  \n",
      "-----------------------------------------|-----------|-----------\n",
      "t5-small                                 | 5.442e-09 | 7.920e+02\n",
      "t5-base                                  | 1.273e-10 | 5.600e+02\n",
      "t5-large                                 | 3.638e-11 | 5.200e+02\n",
      "google/mt5-small                         | 3.201e-09 | 1.140e+02\n",
      "google/mt5-base                          | 1.848e-09 | 1.135e+02\n",
      "google/mt5-large                         | 1.892e-10 | 1.750e+02\n",
      "google/bigbird-pegasus-large-arxiv       | 0.000e+00 | 2.424e+02\n",
      "google/pegasus-cnn_dailymail             | 0.000e+00 | 2.416e+02\n",
      "google/pegasus-large                     | 0.000e+00 | 2.417e+02\n",
      "google/pegasus-multi_news                | 0.000e+00 | 2.412e+02\n",
      "google/pegasus-xsum                      | 0.000e+00 | 2.418e+02\n"
     ]
    }
   ],
   "source": [
    "# bf16-pretrained models\n",
    "mnames = [\"t5-small\", \"t5-base\", \"t5-large\", \"google/mt5-small\", \"google/mt5-base\", \"google/mt5-large\",\n",
    "          \"google/bigbird-pegasus-large-arxiv\", \"google/pegasus-cnn_dailymail\", \"google/pegasus-large\", \"google/pegasus-multi_news\", \"google/pegasus-xsum\"\n",
    "]\n",
    "models_abs_min_max(mnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31280426",
   "metadata": {},
   "source": [
    "We can see big abs max weight values - pretty consistently - so perhaps if the max weight > 1e2 it's a good candidate for bf16 group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f92dc2",
   "metadata": {},
   "source": [
    "## fp16 models\n",
    "\n",
    "Let's look at fp16-pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a74dfcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name                   |  abs min  |  abs max  \n",
      "-----------------------------------------|-----------|-----------\n",
      "allenai/longformer-base-4096             | 0.000e+00 | 1.510e+00\n",
      "allenai/longformer-large-4096            | 0.000e+00 | 1.146e+00\n",
      "allenai/led-base-16384                   | 0.000e+00 | 1.600e+01\n",
      "allenai/led-large-16384                  | 0.000e+00 | 2.320e+01\n",
      "lvwerra/codeparrot                       | 6.578e-12 | 1.671e+00\n"
     ]
    }
   ],
   "source": [
    "# fp16-pretrained models\n",
    "mnames = [\"allenai/longformer-base-4096\", \"allenai/longformer-large-4096\", \n",
    "          \"allenai/led-base-16384\", \"allenai/led-large-16384\", \"lvwerra/codeparrot\"\n",
    "         ]\n",
    "models_abs_min_max(mnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3500cd2b",
   "metadata": {},
   "source": [
    "So we can see the fp16 abs max weights are quite small - they are in the range of 1e0 - 1e1.\n",
    "\n",
    "\"led\" ones are oddly pretty high. they are supposed to be the same as longformer, which are fp16."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33149dff",
   "metadata": {},
   "source": [
    "## fp32 models\n",
    "\n",
    "Let's look at fp32-pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e0226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name                   |  abs min  |  abs max  \n",
      "-----------------------------------------|-----------|-----------\n",
      "gsarti/it5-small                         | 6.114e-08 | 4.693e+02\n",
      "gsarti/it5-base                          | 1.068e-08 | 1.598e+03\n",
      "gsarti/it5-base-oscar                    | 3.638e-12 | 2.092e+01\n",
      "gsarti/it5-large                         | 2.094e-09 | 4.388e+04\n"
     ]
    }
   ],
   "source": [
    "# fp32-pretrained models\n",
    "mnames = [\"gsarti/it5-small\", \"gsarti/it5-base\", \"gsarti/it5-base-oscar\", \"gsarti/it5-large\", \"EleutherAI/gpt-neo-2.7B\", ]\n",
    "models_abs_min_max(mnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081c1126",
   "metadata": {},
   "source": [
    "Big abs max numbers\n",
    "\n",
    "XXX: I suspect \"EleutherAI/gpt-neo-2.7B\" is in the wrong category as its abs max is very low. need more data inputs.\n",
    "\n",
    "XXX: need more inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a447e780",
   "metadata": {},
   "source": [
    "## Unknown models\n",
    "\n",
    "Let's look at some uknown models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6e8df28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name                   |  abs min  |  abs max  \n",
      "-----------------------------------------|-----------|-----------\n",
      "bigscience/T0_3B                         | 5.755e-13 | 1.680e+02\n"
     ]
    }
   ],
   "source": [
    "# fp32? (XXX: need to check)\n",
    "mnames = [\"bigscience/T0_3B\"] \n",
    "# mnames = [\"bigscience/T0pp\", \"bigscience/T0_3B\"] \"bigscience/T0pp\" is huge!\n",
    "models_abs_min_max(mnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb4a50",
   "metadata": {},
   "source": [
    "need to check how it was trained - looks like bf16 to me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16f37c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp32? (XXX: need to check)\n",
    "#mnames = [\"google/pegasus-pubmed\"] \n",
    "#mnames = [\"EleutherAI/gpt-neo-1.3B\"] \n",
    "# mnames = [\"bigscience/T0pp\", \"bigscience/T0_3B\"] \"bigscience/T0pp\" is huge!\n",
    "\n",
    "#mnames = [\"\"] \n",
    "#models_abs_min_max(mnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af36a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "17e58755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision                                                       \n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f2ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2b5ae7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, dtype):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.linear = nn.Linear(input_size, 3, bias=False)\n",
    "        if dtype == torch.bfloat16:\n",
    "            self.linear.weight = nn.Parameter(self.linear.weight * 3)\n",
    "        else:\n",
    "            self.linear.weight = nn.Parameter(self.linear.weight / 10.)\n",
    "            \n",
    "        self.non_lin = nn.ReLU()\n",
    "        self.output = nn.Linear(3, output_size, bias=False)\n",
    "        if dtype == torch.bfloat16:\n",
    "            self.output.weight = nn.Parameter(self.output.weight * 3)\n",
    "        else:\n",
    "            self.output.weight = nn.Parameter(self.output.weight / 10.)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        inputs = self.linear(inputs)\n",
    "        inputs = self.non_lin(inputs)\n",
    "        return self.output(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0775f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "dataset_input = torch.randn((1000, 4), device=device)\n",
    "dataset_label = (0.1 * (torch.randint(0, 10, (1000,), device=device)) + 5 ).long() * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9e3ca4f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.751953125\n",
      "2.7734375\n",
      "1.1162109375\n",
      "0.1075439453125\n",
      "0.0081787109375\n",
      "0.0009007453918457031\n",
      "0.00014412403106689453\n",
      "2.4437904357910156e-05\n",
      "5.125999450683594e-06\n",
      "finished\n",
      "4.1875\n",
      "4.0\n",
      "3.65625\n",
      "2.28125\n",
      "0.2734375\n",
      "0.01104736328125\n",
      "0.0004291534423828125\n",
      "1.239776611328125e-05\n",
      "2.384185791015625e-07\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for j, dtype in enumerate((torch.float16, torch.bfloat16)):\n",
    "    \n",
    "    random.seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "  \n",
    "    model = MyModel(4, 60, dtype=dtype).to(device=device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    f_loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(9):\n",
    "        for i in range(1000):\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=True, dtype=dtype):\n",
    "                output = model(dataset_input[i].unsqueeze(0))\n",
    "                loss = f_loss(output, dataset_label[i].unsqueeze(0))\n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if dtype==torch.bfloat16:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    scaler.scale(loss).backward()\n",
    "\n",
    "                    # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "                    # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "                    # otherwise, optimizer.step() is skipped.\n",
    "                    scaler.step(optimizer)\n",
    "\n",
    "                    # Updates the scale for next iteration.\n",
    "                    scaler.update()\n",
    "\n",
    "        print(loss.item())\n",
    "            \n",
    "            \n",
    "    for name, parameter in model.named_parameters():\n",
    "        u, s, v = torch.svd_lowrank(parameter, q=3)\n",
    "        \n",
    "        data[f\"{j}_{dtype}_{name}\"] = parameter\n",
    "    \n",
    "        data[f\"{j}_{dtype}_{name}_u\"] = u\n",
    "        data[f\"{j}_{dtype}_{name}_s\"] = s\n",
    "        data[f\"{j}_{dtype}_{name}_v\"] = v\n",
    "    \n",
    "    print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ae31a9b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4757,  0.6781, -0.5603],\n",
      "        [ 0.7616, -0.0011, -0.6480],\n",
      "        [-0.4400, -0.7350, -0.5159]], device='cuda:0',\n",
      "       grad_fn=<LinalgSvdBackward0>)\n",
      "tensor([3.2457, 2.2845, 0.1098], device='cuda:0', grad_fn=<LinalgSvdBackward0>)\n",
      "tensor([[-0.3599,  0.7246,  0.5300],\n",
      "        [-0.5523, -0.4250,  0.4669],\n",
      "        [ 0.1861, -0.5160,  0.5169],\n",
      "        [ 0.7286,  0.1676,  0.4837]], device='cuda:0', grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for x in (\"u\", \"s\", \"v\"):\n",
    "    print(data[f'0_torch.float16_linear.weight_{x}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "73aa9221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1856, -0.9520,  0.2434],\n",
      "        [ 0.6623,  0.0618,  0.7467],\n",
      "        [-0.7259,  0.2998,  0.6190]], device='cuda:0',\n",
      "       grad_fn=<LinalgSvdBackward0>)\n",
      "tensor([3.6283, 1.8956, 0.3372], device='cuda:0', grad_fn=<LinalgSvdBackward0>)\n",
      "tensor([[-0.1361, -0.2753, -0.9333],\n",
      "        [-0.1401, -0.1053,  0.2421],\n",
      "        [ 0.4078,  0.8456, -0.2649],\n",
      "        [ 0.8920, -0.4451,  0.0167]], device='cuda:0', grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for x in (\"u\", \"s\", \"v\"):\n",
    "    print(data[f'1_torch.bfloat16_linear.weight_{x}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "16a0f8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.6456,  0.1657, -1.1185, -0.8951],\n",
      "        [-0.9291, -1.3975,  0.4246,  1.7662],\n",
      "        [-0.7328,  1.4759,  0.5712, -1.3493]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.0909, -3.2617, -2.9867],\n",
      "        [-3.0261, -3.1987, -2.9237],\n",
      "        [-3.0696, -3.2513, -2.9388],\n",
      "        [-2.9730, -3.2431, -2.9065],\n",
      "        [-3.0353, -3.2192, -2.9048],\n",
      "        [-3.0885, -3.2604, -2.9769],\n",
      "        [-3.0623, -3.1596, -3.0052],\n",
      "        [-3.0633, -3.2635, -3.0158],\n",
      "        [-3.0674, -3.1641, -2.9391],\n",
      "        [-3.0043, -3.2185, -2.9878],\n",
      "        [-3.0221, -3.2824, -2.9980],\n",
      "        [-3.0613, -3.1806, -2.9290],\n",
      "        [-3.0543, -3.2264, -2.9223],\n",
      "        [-2.9691, -3.2000, -2.9461],\n",
      "        [-2.9860, -3.2657, -2.9405],\n",
      "        [-3.0804, -3.2640, -2.9919],\n",
      "        [-3.0080, -3.1943, -2.9946],\n",
      "        [-3.0149, -3.1858, -2.9676],\n",
      "        [-3.0253, -3.2099, -2.9217],\n",
      "        [-2.9709, -3.2762, -2.9719],\n",
      "        [-3.0029, -3.1717, -2.9066],\n",
      "        [-2.9822, -3.2084, -3.0078],\n",
      "        [-3.0292, -3.2606, -3.0127],\n",
      "        [-2.9842, -3.1695, -3.0182],\n",
      "        [-3.0200, -3.2339, -2.9672],\n",
      "        [-3.0646, -3.1923, -2.9999],\n",
      "        [-3.0048, -3.1931, -2.9152],\n",
      "        [-3.0087, -3.2873, -2.9918],\n",
      "        [-3.0056, -3.2067, -3.0048],\n",
      "        [-3.0656, -3.1597, -2.9255],\n",
      "        [-3.0634, -3.2337, -3.0187],\n",
      "        [-3.0347, -3.2694, -3.0029],\n",
      "        [-3.0377, -3.2104, -2.9853],\n",
      "        [-2.9856, -3.2701, -2.8965],\n",
      "        [-2.9872, -3.2805, -2.9662],\n",
      "        [-3.0272, -3.2140, -2.9450],\n",
      "        [-3.0100, -3.2176, -2.9869],\n",
      "        [-3.0024, -3.2859, -2.9881],\n",
      "        [-3.0474, -3.2529, -2.9798],\n",
      "        [-3.0800, -3.2349, -2.9498],\n",
      "        [-3.0668, -3.2270, -2.9188],\n",
      "        [-3.0382, -3.2199, -2.9651],\n",
      "        [-3.0140, -3.1846, -2.9025],\n",
      "        [-2.9949, -3.1600, -2.9640],\n",
      "        [-3.0810, -3.2545, -2.9202],\n",
      "        [-3.0348, -3.2525, -3.0038],\n",
      "        [-3.0879, -3.2749, -2.9730],\n",
      "        [-3.0047, -3.1836, -3.0174],\n",
      "        [-2.9910, -3.2765, -2.9645],\n",
      "        [-3.0571, -3.2333, -2.9727],\n",
      "        [ 2.9798,  3.1726,  2.9504],\n",
      "        [-3.0263, -3.2550, -2.9336],\n",
      "        [-3.0812, -3.2280, -2.9100],\n",
      "        [-3.0572, -3.1614, -2.9435],\n",
      "        [-3.0902, -3.1759, -2.9745],\n",
      "        [-3.0666, -3.1628, -3.0150],\n",
      "        [-3.0189, -3.2405, -2.9135],\n",
      "        [-3.0128, -3.1927, -2.9379],\n",
      "        [-3.0507, -3.2320, -3.0100],\n",
      "        [-2.9950, -3.1737, -2.9171]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for x in (\"linear\", \"output\"):\n",
    "    print(data[f'0_torch.float16_{x}.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2e4932ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5118,  0.3042, -1.8223,  0.2039],\n",
      "        [-0.5942, -0.2880,  1.0123,  2.0953],\n",
      "        [ 0.0071,  0.3596, -0.6487, -2.5987]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-4.4419, -4.9634, -4.3817],\n",
      "        [-2.9160, -3.0629, -2.7884],\n",
      "        [-4.1905, -4.6531, -3.2930],\n",
      "        [-0.4725, -3.3024, -0.9470],\n",
      "        [-3.3107, -3.7164, -2.3899],\n",
      "        [-4.4433, -4.9202, -4.1564],\n",
      "        [-3.5436, -1.4986, -4.4286],\n",
      "        [-3.4613, -5.0607, -5.1958],\n",
      "        [-4.0473, -1.5142, -2.7730],\n",
      "        [-1.8561, -3.8900, -4.3769],\n",
      "        [-2.3192, -5.5579, -4.8079],\n",
      "        [-4.0529, -2.3221, -2.7766],\n",
      "        [-3.8760, -3.9557, -2.8824],\n",
      "        [-0.2306, -2.4180, -2.1388],\n",
      "        [-1.2093, -4.8995, -2.8423],\n",
      "        [-4.1038, -5.0288, -4.5613],\n",
      "        [-2.0090, -3.0834, -4.5075],\n",
      "        [-2.3666, -2.6742, -3.8056],\n",
      "        [-2.8977, -3.4578, -2.7808],\n",
      "        [-0.3357, -4.9915, -3.4214],\n",
      "        [-1.7502, -1.6765, -1.5579],\n",
      "        [-0.8048, -3.5790, -4.5389],\n",
      "        [-2.4829, -5.0370, -5.1643],\n",
      "        [-0.9278, -2.0825, -4.6137],\n",
      "        [-2.4998, -4.2839, -4.0042],\n",
      "        [-3.7818, -2.9778, -4.6614],\n",
      "        [-2.0236, -2.7549, -2.2046],\n",
      "        [-1.9007, -5.6943, -4.6004],\n",
      "        [-1.8497, -3.5475, -4.7965],\n",
      "        [-3.9569, -1.1794, -2.3032],\n",
      "        [-3.5146, -4.3009, -5.2434],\n",
      "        [-2.6969, -5.2310, -4.9397],\n",
      "        [-3.0324, -3.5839, -4.4497],\n",
      "        [-1.1692, -4.5088, -1.2816],\n",
      "        [-1.1784, -5.4390, -3.6473],\n",
      "        [-2.8891, -3.6375, -3.4287],\n",
      "        [-2.0753, -3.8593, -4.4060],\n",
      "        [-1.6883, -5.6669, -4.4468],\n",
      "        [-3.2633, -4.7668, -4.3690],\n",
      "        [-4.4553, -4.2293, -3.4943],\n",
      "        [-4.2752, -3.9635, -2.7446],\n",
      "        [-3.1437, -3.8463, -3.9787],\n",
      "        [-2.3573, -2.3726, -1.8725],\n",
      "        [-1.4033, -1.3287, -3.0406],\n",
      "        [-4.6340, -4.7124, -2.7629],\n",
      "        [-2.7265, -4.8092, -4.9508],\n",
      "        [-4.4315, -5.2667, -4.0727],\n",
      "        [-1.8000, -2.7150, -4.9971],\n",
      "        [-1.3535, -5.3647, -3.6639],\n",
      "        [-3.6391, -4.2246, -4.1554],\n",
      "        [ 1.2187,  2.2229,  3.2045],\n",
      "        [-2.8537, -4.7942, -3.1981],\n",
      "        [-4.7412, -3.9762, -2.4346],\n",
      "        [-3.6646, -1.3561, -2.8693],\n",
      "        [-4.6493, -2.2637, -3.7564],\n",
      "        [-3.6628, -1.7340, -4.7200],\n",
      "        [-2.6589, -4.3691, -2.5699],\n",
      "        [-2.3692, -2.8685, -3.0278],\n",
      "        [-3.2079, -4.2578, -5.0685],\n",
      "        [-1.4336, -1.7821, -1.7491]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for x in (\"linear\", \"output\"):\n",
    "    print(data[f'1_torch.bfloat16_{x}.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ee5a7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fp16_to_bf16(weight, q=6):\n",
    "    # basic: convert each sep\n",
    "    \n",
    "    u, s, v = torch.svd_lowrank(weight, q=q, niter=10)\n",
    "    return u, s, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4a337e90",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "(torch.Size([3, 3]), 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [177], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, parameter \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[0;32m----> 2\u001b[0m     u, s, v \u001b[38;5;241m=\u001b[39m \u001b[43mfp16_to_bf16\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameter\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [176], line 4\u001b[0m, in \u001b[0;36mfp16_to_bf16\u001b[0;34m(weight, q)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfp16_to_bf16\u001b[39m(weight, q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# basic: convert each sep\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     u, s, v \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd_lowrank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m u, s, v\n",
      "File \u001b[0;32m~/.env/pytorch/lib/python3.10/site-packages/torch/_lowrank.py:137\u001b[0m, in \u001b[0;36msvd_lowrank\u001b[0;34m(A, q, niter, M)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtype\u001b[39m, tensor_ops))\u001b[38;5;241m.\u001b[39missubset(\n\u001b[1;32m    132\u001b[0m         (torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    133\u001b[0m     ) \u001b[38;5;129;01mand\u001b[39;00m has_torch_function(tensor_ops):\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    135\u001b[0m             svd_lowrank, tensor_ops, A, q\u001b[38;5;241m=\u001b[39mq, niter\u001b[38;5;241m=\u001b[39mniter, M\u001b[38;5;241m=\u001b[39mM\n\u001b[1;32m    136\u001b[0m         )\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_svd_lowrank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mniter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mniter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/pytorch/lib/python3.10/site-packages/torch/_lowrank.py:168\u001b[0m, in \u001b[0;36m_svd_lowrank\u001b[0;34m(A, q, niter, M)\u001b[0m\n\u001b[1;32m    166\u001b[0m     B_t \u001b[38;5;241m=\u001b[39m matmul(A, Q_c) \u001b[38;5;241m-\u001b[39m matmul(M, Q_c)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m B_t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m m, (B_t\u001b[38;5;241m.\u001b[39mshape, m)\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m B_t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m q, (B_t\u001b[38;5;241m.\u001b[39mshape, q)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m B_t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m B_t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], B_t\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    170\u001b[0m U, S, Vh \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msvd(B_t, full_matrices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: (torch.Size([3, 3]), 6)"
     ]
    }
   ],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    u, s, v = fp16_to_bf16(parameter) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8b1cc9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.0611,  0.1330, -1.7605,  0.1466],\n",
      "        [-0.7716, -0.2960,  1.1901,  2.2352],\n",
      "        [-0.0403,  0.3733, -0.5693, -2.6609]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-3.9159, -4.2902, -4.0074],\n",
      "        [-2.6747, -2.9679, -2.6374],\n",
      "        [-3.6547, -4.0776, -3.1965],\n",
      "        [-1.1376, -3.5658, -1.4755],\n",
      "        [-2.9043, -3.4260, -2.3562],\n",
      "        [-3.9046, -4.2604, -3.8511],\n",
      "        [-3.3239, -1.9507, -4.1121],\n",
      "        [-3.2540, -4.3546, -4.4939],\n",
      "        [-3.6044, -1.9820, -2.9902],\n",
      "        [-2.0055, -3.5081, -3.7839],\n",
      "        [-2.3974, -4.7042, -4.1317],\n",
      "        [-3.5135, -2.4737, -2.8746],\n",
      "        [-3.3641, -3.5888, -2.8332],\n",
      "        [-0.9957, -2.8861, -2.3710],\n",
      "        [-1.5866, -4.2982, -2.6797],\n",
      "        [-3.6862, -4.3365, -4.1030],\n",
      "        [-2.1020, -2.9508, -3.8896],\n",
      "        [-2.3492, -2.6882, -3.4017],\n",
      "        [-2.6588, -3.2364, -2.6149],\n",
      "        [-1.0227, -4.4652, -3.2033],\n",
      "        [-1.9665, -2.1739, -1.8420],\n",
      "        [-1.2726, -3.3118, -3.9496],\n",
      "        [-2.5283, -4.3307, -4.3942],\n",
      "        [-1.3413, -2.3135, -4.0655],\n",
      "        [-2.4632, -3.7983, -3.5229],\n",
      "        [-3.4194, -2.8780, -4.1572],\n",
      "        [-2.0788, -2.7962, -2.1693],\n",
      "        [-2.0808, -4.7921, -3.9656],\n",
      "        [-1.9980, -3.2654, -4.0889],\n",
      "        [-3.5653, -1.8077, -2.7016],\n",
      "        [-3.2813, -3.8062, -4.5239],\n",
      "        [-2.6803, -4.4737, -4.2473],\n",
      "        [-2.8596, -3.3028, -3.9003],\n",
      "        [-1.5199, -4.1593, -1.5349],\n",
      "        [-1.5643, -4.6262, -3.2834],\n",
      "        [-2.6949, -3.3527, -3.1123],\n",
      "        [-2.1609, -3.4884, -3.8051],\n",
      "        [-1.9231, -4.7669, -3.8524],\n",
      "        [-3.0583, -4.1479, -3.8725],\n",
      "        [-3.8560, -3.7697, -3.3829],\n",
      "        [-3.6453, -3.5935, -2.8057],\n",
      "        [-2.9173, -3.4935, -3.5576],\n",
      "        [-2.2856, -2.5579, -1.9568],\n",
      "        [-1.7839, -1.8945, -3.0339],\n",
      "        [-3.9329, -4.1244, -2.8829],\n",
      "        [-2.6949, -4.1705, -4.2525],\n",
      "        [-3.8950, -4.5112, -3.7919],\n",
      "        [-1.9580, -2.7017, -4.2606],\n",
      "        [-1.6814, -4.5647, -3.2842],\n",
      "        [-3.3084, -3.7611, -3.7534],\n",
      "        [ 1.6819,  2.4937,  3.0662],\n",
      "        [-2.6795, -4.1715, -2.9375],\n",
      "        [-3.9633, -3.6030, -2.6700],\n",
      "        [-3.3674, -1.8966, -3.0372],\n",
      "        [-4.0097, -2.4085, -3.6645],\n",
      "        [-3.3919, -2.0825, -4.2951],\n",
      "        [-2.4937, -3.8754, -2.4265],\n",
      "        [-2.3258, -2.8296, -2.7955],\n",
      "        [-3.0465, -3.7761, -4.3718],\n",
      "        [-1.7695, -2.2439, -1.9860]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    #bf16_weight = fp16_to_bf16(parameter) \n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed27d074",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3891572883.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [74], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Parameter containing:\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#bf16\n",
    "Parameter containing:\n",
    "tensor([[-0.1229, -0.6971, -0.0126,  0.3644],\n",
    "        [ 0.4843,  0.5767,  0.0836,  0.4326],\n",
    "        [-0.1458, -0.1250, -0.5431, -0.6094]], device='cuda:0',\n",
    "       requires_grad=True)\n",
    "\n",
    "\n",
    "#fb16\n",
    "tensor([[-0.6800,  0.8049,  0.4577,  0.3503],\n",
    "        [ 0.2505, -0.3497,  0.0312,  0.3005],\n",
    "        [-0.5663,  0.8540,  0.1833,  0.6032]], device='cuda:0',\n",
    "       requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.svd_lowrank(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87a092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

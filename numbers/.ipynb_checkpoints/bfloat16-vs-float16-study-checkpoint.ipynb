{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fancy-procurement",
   "metadata": {},
   "source": [
    "# float16 vs bfloat16 numerical properties comparsion\n",
    "\n",
    "This a short notebook to help understand `fp16` vs `bfloat16` in particular when converting a model trained\n",
    "in `bfloat16` to mixed precision - it should be possible to look at the numbers to know which ranges\n",
    "are safe and which need to be scaled/avoided.\n",
    "\n",
    "I needed to do that in the context of trying to understand why bfloat16 t5/mt5 models that were pretrained in bfloat16 had a lot of `nan`/`inf` problems when finetuned in mixed precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "international-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-balloon",
   "metadata": {},
   "source": [
    "This is the main function, that tries to do very simply math in `bfloat16` and the converting the numbers to `float16` and showing the discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coastal-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mismatch(start, incr):\n",
    "    bf16 = torch.tensor(start, dtype=torch.bfloat16)\n",
    "    print(f\"\\nfp32 start={start:.2e} using increment={incr}\")\n",
    "    print(f\"{'bfloat16':>18} {'float16':>18} {'diff':>8}\")\n",
    "    c = 0\n",
    "    tries = 0\n",
    "    while c < 8:\n",
    "        fp16 = bf16.to(torch.float16)\n",
    "        if not (fp16 == bf16):\n",
    "            print(f\"{bf16:.16f} {fp16:.16f} {torch.sub(fp16.to(dtype=torch.float32), bf16):+.2e}\")\n",
    "            c += 1\n",
    "        bf16 += incr\n",
    "        tries += 1\n",
    "        if tries >= 1e5:\n",
    "            print(f\"gave up finding mismatch after {tries} steps\")\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-cartridge",
   "metadata": {},
   "source": [
    "Large numbers range\n",
    "\n",
    "float16: Â±65,504"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-capability",
   "metadata": {},
   "source": [
    "## underflow for fp16\n",
    "\n",
    "when numbers become 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fatal-nutrition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fp32 start=1.00e-08 using increment=1e-09\n",
      "          bfloat16            float16     diff\n",
      "0.0000000100117177 0.0000000000000000 -1.00e-08\n",
      "0.0000000110012479 0.0000000000000000 -1.10e-08\n",
      "0.0000000119907781 0.0000000000000000 -1.20e-08\n",
      "0.0000000129803084 0.0000000000000000 -1.30e-08\n",
      "0.0000000139698386 0.0000000000000000 -1.40e-08\n",
      "0.0000000150175765 0.0000000000000000 -1.50e-08\n",
      "0.0000000160653144 0.0000000000000000 -1.61e-08\n",
      "0.0000000171130523 0.0000000000000000 -1.71e-08\n"
     ]
    }
   ],
   "source": [
    "find_mismatch(1e-08, 1e-09)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-employment",
   "metadata": {},
   "source": [
    "## subnormal range for fp16\n",
    "\n",
    "starting from 5.96e-8 \n",
    "\n",
    "usually expensive and very low precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "natural-carrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fp32 start=1.00e-07 using increment=1e-08\n",
      "          bfloat16            float16     diff\n",
      "0.0000001001171768 0.0000001192092896 +1.91e-08\n",
      "0.0000001098960638 0.0000001192092896 +9.31e-09\n",
      "0.0000001201406121 0.0000001192092896 -9.31e-10\n",
      "0.0000001303851604 0.0000001192092896 -1.12e-08\n",
      "0.0000001406297088 0.0000001192092896 -2.14e-08\n",
      "0.0000001508742571 0.0000001788139343 +2.79e-08\n",
      "0.0000001611188054 0.0000001788139343 +1.77e-08\n",
      "0.0000001713633537 0.0000001788139343 +7.45e-09\n"
     ]
    }
   ],
   "source": [
    "# very limited range for fp16\n",
    "find_mismatch(1e-07, 1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "instant-poverty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fp32 start=1.00e-06 using increment=1e-07\n",
      "          bfloat16            float16     diff\n",
      "0.0000009983778000 0.0000010132789612 +1.49e-08\n",
      "0.0000010952353477 0.0000010728836060 -2.24e-08\n",
      "0.0000012889504433 0.0000013113021851 +2.24e-08\n",
      "0.0000013858079910 0.0000013709068298 -1.49e-08\n",
      "0.0000014826655388 0.0000014901161194 +7.45e-09\n",
      "0.0000015795230865 0.0000015497207642 -2.98e-08\n",
      "0.0000016763806343 0.0000016689300537 -7.45e-09\n",
      "0.0000017732381821 0.0000017881393433 +1.49e-08\n"
     ]
    }
   ],
   "source": [
    "# things starting to improve slightly for fp16\n",
    "find_mismatch(1e-06, 1e-07)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-window",
   "metadata": {},
   "source": [
    "## normal numbers start\n",
    "min positive normal fp16: 6.104e-05 (np.finfo(np.float16).tiny)\n",
    "\n",
    "these ranges match much better and thus will not easily find a mismatch if at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "educational-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fp32 start=1.00e-05 using increment=1e-06\n",
      "          bfloat16            float16     diff\n",
      "gave up finding mismatch after 100000 steps\n",
      "\n",
      "fp32 start=1.00e-04 using increment=1e-06\n",
      "          bfloat16            float16     diff\n",
      "gave up finding mismatch after 100000 steps\n",
      "\n",
      "fp32 start=1.00e-03 using increment=0.0001\n",
      "          bfloat16            float16     diff\n",
      "gave up finding mismatch after 100000 steps\n",
      "\n",
      "fp32 start=1.00e-02 using increment=0.001\n",
      "          bfloat16            float16     diff\n",
      "gave up finding mismatch after 100000 steps\n",
      "\n",
      "fp32 start=1.00e-01 using increment=0.01\n",
      "          bfloat16            float16     diff\n",
      "gave up finding mismatch after 100000 steps\n",
      "\n",
      "fp32 start=1.00e+01 using increment=1e-06\n",
      "          bfloat16            float16     diff\n",
      "gave up finding mismatch after 100000 steps\n",
      "\n",
      "fp32 start=1.00e+01 using increment=10.0\n",
      "          bfloat16            float16     diff\n",
      "gave up finding mismatch after 100000 steps\n",
      "\n",
      "fp32 start=1.00e+04 using increment=1\n",
      "          bfloat16            float16     diff\n",
      "gave up finding mismatch after 100000 steps\n"
     ]
    }
   ],
   "source": [
    "find_mismatch(1e-05, 1e-06)\n",
    "find_mismatch(1e-04, 1e-06)\n",
    "find_mismatch(1e-03, 1e-04)\n",
    "find_mismatch(1e-02, 1e-03)\n",
    "find_mismatch(1e-01, 1e-02)\n",
    "find_mismatch(1e1, 1e-06)\n",
    "find_mismatch(1e1, 1e1)\n",
    "find_mismatch(1e4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "proprietary-youth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fp32 start=5.00e+04 using increment=1000.0\n",
      "          bfloat16            float16     diff\n",
      "66048.0000000000000000 inf +inf\n",
      "67072.0000000000000000 inf +inf\n",
      "68096.0000000000000000 inf +inf\n",
      "69120.0000000000000000 inf +inf\n",
      "70144.0000000000000000 inf +inf\n",
      "71168.0000000000000000 inf +inf\n",
      "72192.0000000000000000 inf +inf\n",
      "73216.0000000000000000 inf +inf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hitting max range for fp16\n",
    "find_mismatch(5e4, 1e3)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "solid-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- roundoff ---\n",
    "# fp16 4.88e-4\n",
    "# bf16 3.91e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-priority",
   "metadata": {},
   "source": [
    "## Big numbers\n",
    "\n",
    "`bfloat16` numbers have a terrible range for numbers > 1 but fp16 matches those exactly\n",
    "e.g. one can't represent 283 in bf16\n",
    "\n",
    "```\n",
    "python -c \"import torch; print( torch.tensor(283, dtype=torch.bfloat16) )\"\n",
    "tensor(284., dtype=torch.bfloat16)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "close-discovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282.0000000000000000\n",
      "284.0000000000000000\n",
      "286.0000000000000000\n"
     ]
    }
   ],
   "source": [
    "start = 280\n",
    "fp32 = torch.tensor(start, dtype=torch.float32)\n",
    "for i in range(3):\n",
    "    bf16 = fp32.to(torch.bfloat16)\n",
    "    bf16d = bf16\n",
    "    while bf16 == bf16d:\n",
    "        fp32 += 1\n",
    "        bf16d = fp32.to(torch.bfloat16)\n",
    "    print(f\"{bf16d:.16f}\")\n",
    "# 282\n",
    "# 284\n",
    "# 286"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-panama",
   "metadata": {},
   "source": [
    "## Summation\n",
    "\n",
    "a very narrow dynamic range means that for largish numbers NN trained in bfloat16 **expects** bad\n",
    "precision and when the precision is suddenly higher unexpected outcomes happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "complete-advancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(284., dtype=torch.bfloat16)\n",
      "tensor(283., dtype=torch.float16)\n",
      "tensor(2848., dtype=torch.bfloat16)\n",
      "tensor(2830., dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# small sum\n",
    "print(torch.tensor(282, dtype=torch.bfloat16)+1) # 284\n",
    "print(torch.tensor(282, dtype=torch.float16)+1)  # 283\n",
    "\n",
    "# sum several of these\n",
    "print(torch.tensor(283, dtype=torch.bfloat16)*10) # 2848\n",
    "print(torch.tensor(283, dtype=torch.float16)*10)  # 2830"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-category",
   "metadata": {},
   "source": [
    "# disabling subnormal numbers in pytorch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "korean-cause",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-39])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0133e-06], dtype=torch.float16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0133e-06], dtype=torch.float16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0102e-39], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "torch.set_flush_denormal(True)\n",
    "torch.tensor([1e-39], dtype=torch.float32)\n",
    "torch.set_flush_denormal(False)\n",
    "torch.tensor([1e-39], dtype=torch.float32)\n",
    "\n",
    "# broken for fp16\n",
    "torch.set_flush_denormal(True)\n",
    "torch.tensor([1e-6], dtype=torch.float16)\n",
    "torch.set_flush_denormal(False)\n",
    "torch.tensor([1e-6], dtype=torch.float16)\n",
    "\n",
    "torch.set_flush_denormal(True)\n",
    "torch.tensor([1e-39], dtype=torch.bfloat16)\n",
    "torch.set_flush_denormal(False)\n",
    "torch.tensor([1e-39], dtype=torch.bfloat16)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
